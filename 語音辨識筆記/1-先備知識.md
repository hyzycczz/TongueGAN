
# 監督式學習與非監督式學習
聲音學習中主要可以分為監督式學習與非監督式學習，監督式學習就是藉由每次的結果做參數修正，非監督式學習就有點像是分群的概念。
## 監督式學習
在進行說話人辨識中常用到的監督式學習有，KNN (K Nearest Neighbor)、ANN (人工神經網路)、SVM (支持向量)。
* KNN (K Nearest Neighbor)：
簡單來說就是找K個最近的資料分為一群，根據這K個裡面的資料將其分類。但由於需要儲存所有的特徵向量，而且需要將需要辨識的聲音與所有模型做向量的相似運算 ( 運算方式可能有很多種 )。

* 人工神經網路：
也就是所謂的黑箱機制，無法觀察學習的過程，也很難依靠人工推算出一定的結果，並且常常需要耗費大量運算資源，有時甚至達不到學習目的。
但此演算法擁有很翔的"聚類能力"，包含有動態聚類、模糊聚類、圖論據類之類的。

## 非監督式學習
非監督式學習透過適當的資料處理語聚類，讓音訊可以自己判斷出最合適的結果並輸出。在語音辨識上最常用到的模型有有：
* 隱藏式馬可夫模型 (HMM)+ deeplearning：
HMM是時間序列結構的統計模型，運作方式將內部狀態之間的轉換以及各狀態呈現的觀察值來描述整個資料的模型。但是只能得到觀測值 不能知道內部狀態的轉換過程，因此稱之為隱藏。

* 高斯混和模型 (GMM) + deeplearning：
透過輸入聲音的特徵值，並計算出平均描述特徵參數的分布位置、共變異矩陣來描述聲音形狀的變化等統計方式。，因此高師混和模型可以很平滑的描述聲音的特徵分布，並計算機路密度函數作為分類的依據。此方法可以運用在分辨發音性別與年齡。缺點是當模型過多的時候，訓練和辨識的計算量都較大。

# 總流程圖
![[speech recognize process.PNG]]

# 預處理流程圖
![[speech recognize preprocess procedure.PNG]]

# 語音辨識的基本單位

## Phoneme
Phoneme 是發音的基本單位，可以想像成KK音標( 但其實不完全一樣 )。
用這種作法，會需要一張 Lexicon 來對照，將Phoneme 轉換成word。這種作法有的優點就是聲音與Phoneme的關係非常的明確，分析起來也比較容易，但缺點也很明顯，在面對新的語言的時候，常常需要專業的語言學家的協助，並且，當出現一個重來沒有出現過的字的時候，就需要更新Lexicon，否則，將沒有辦法辨別。
## Grapheme
在深度學習開始流行後，其他的方法開始漸漸的流行起來。
Grapheme也就是書寫的基本單位，以英文為例就是，A~Z加上"空白鍵"或者再加上一些標點符號。
Grapheme的作法優點就是，面對新的語言的時候，並不需要語言學家，做法可以說是非常的直接，只需要拿到這個語言的語音與詞彙就可以開始做辨識了，而且某些詞彙是沒有出現過的，機器也有可能能夠輸出正確的答案。缺點就是這樣的方法比較複雜，因為文字與聲音的關係非常的複雜，例如英文中的"C"與"K"的發音，當出現這種問題的時候，機器就需要閱讀更長的上下文。
注意：由於是讓機器自己拼，所以機器有可能會拼錯。
## Word
也就是以詞彙來當作辨識的單位，但這種方法並不是一個很好的，因為詞彙的量非常的大，並且難以分析。
## Morpheme
Morpheme是一個比word小，比Grapheme大的單位，可以理解成字首，字尾，例如：unbreakable = un + break + able之類的。
## Bytes
可以以UTF-8的byte sequence 來表示的話，這樣就可以做到 Language independent了。

# 輸入方式
## 音框
因為不可能一次處理所有聲音，因此要將聲音分成一段一段的，這個就是音框。
通常在處理的時候會將音框之間重顛1/2或1/3。
- 通常音框大小為25ms。

## 聲音特徵
* waveform
* spectrogram
* 39-dim MFCC
* 80-dim filter bank output

其實，上面的聲音特徵都是由waveform來的，簡單講解一下之間的關系就是，waveform經過處理會變成spectrogram，在經過處理會變成filter bank output，在處理就會變成MFCC。
以前主要都是用MFCC來做語音辨識，但隨著deep learning的流行，filter bank已經變成聲音辨識中，讀取特徵的主流。

## 訓練的資料
* 輸出的資料需要將輸入的音訊給予翻譯成文字後的答案去做訓練，否則無法訓練。


# 平緩音窗不連續現象
## 漢明窗 ( Hamming Windows)
將音窗乘上漢明窗的原因是因為每個被分開的音窗都將視為獨立的音訊，為了將音框與音框之間的不連續性減少，因此乘上漢明窗使其不會有這麼不明顯的不連續現象

# 預強調 (Pre-emphasis)
為了彌補聲音訊號再空氣中衰弱的問題，目的是提升生音訊號高頻特性，使聲音變得平坦，更能凸顯聲音的共振峰( Formants) 

# 特徵選取 (Feature extraction)
因為聲音的變化很大，如果將音訊直接拿去做比對，不僅聲音訊號數據很大，辨識率也非常有限，因此在音訊中找到適當的特徵參數是非常重要的一件事。

主要可以分成兩大類：
* 頻譜特徵 (Spectral Feature)
* 倒頻譜特徵 (Cepstral Features)

兩種主要的頻譜特徵選取技術
* 線性評估倒頻譜係數 (Linear Prediction Cepstral Coefficients,LPCC)：
是一個可以運用在辨識人聲與樂曲辨識的特徵選取技術，也是線性預估係數(LPC)的延伸。
* **梅爾倒頻譜係數 (Mel Frequency Cepstral Coefficients,MFCC)：**
廣泛用在聲音辨識系統，是基於人耳特性研發的一種演算法，當多人在說話時，可以只鎖定特定聲音聆聽，MFCC充分的模擬了人的聽覺，具有較高的抗噪能力，在語音辨識中MFCC性能優於LPCC


# 濾波器 (Filter bank)
剔除信號中不需要的頻率或者從許多頻率中選擇一個想要的頻率，方法是將音訊的頻域 (Frequency Domain) 分割成數個部分。目前主要有兩種特徵選取技術。