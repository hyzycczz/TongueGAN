# LAS ( Listen, Attend and Spell )
主要分為三個步驟
* Listen
* Attend 
* Spell

這個模型主要有一個問題，必須聽完整段音訊後才能夠做輸出。

# Listen
![[LAS-Listen.png]]
* 顧名思義，就是聽。這邊的Encoder的功用是希望可以將x1、x2、....中的雜訊消除，並且得到與聲音資訊比較相關的h1、h2、....。

## Encoder的作法
* RNN
* CNN
* CNN+RNN ( 比較常見 )
* self-attention Layers 

## downsampling
由於聲音輸入訊號過長，資料過大，因此常常會需要降低取樣，因此就有以下兩種downsampling的方式。因此downsampling在聲音辨識中可以說是非常重要的一環。

如同上面所說的Encoder方式，以下為RNN的downsampling。
* Pyramid RNN：
第一層RNN做正常的RNN，第二層的RNN將第一層的RNN做簡化。
* Pooling overtime：
從聲音訊號中，兩個取其中一個。

![[downsampling001.PNG]]
(左邊為pyramid RNN，右邊為Pooling overtime)

在CNN的downsamping中常使用到的方式為。
* Time-delay DNN (TDNN)：
只留投跟尾巴。
![[downsampling002.PNG|600x500]]

在self-attention Layers的downsampling的方式為。
* Truncated Self-attention：
設定attention 的range。
![[downsampling003.PNG|600x500]]

# Attend

經過 Listen 的步驟過後，也就是經過decoder的運作過後，我們會得到 h1、h2、...hn。接下來會使用match fuction 將每個decoder 的輸出與關鍵字z0做運算，至於match function 做運算的方法可以自己定義，以下提供兩種常見方法。
* Dot product
* Additive Attention

# Spell
